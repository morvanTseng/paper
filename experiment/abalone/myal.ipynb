{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# 直接导入Smote是不行的，必须将路径加入才可以\n",
    "sys.path.append(\"C:Users\\perma\\PycharmProjects\\paper\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from kmeans_smote import KMeansSMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from algorithm.km_smote import Over_Sample\n",
    "from algorithm.under_sample import Under_Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Sex\", \"Length\", \"Diameter\", \"Height\", \"Whole\", \"Shucked\", \"Viscera\", \"Shell\", \"class\"]\n",
    "major_class = list(range(1, 14))\n",
    "data_path = \"C:\\\\Users\\\\perma\\\\PycharmProjects\\\\paper\\\\data\\\\abalone.data\"\n",
    "\n",
    "table = pd.read_table(filepath_or_buffer=data_path,\n",
    "                      header=None,\n",
    "                      index_col=None,\n",
    "                      names=names,\n",
    "                      sep=\",\"\n",
    "                      )\n",
    "label = []\n",
    "for l in table[\"class\"]:\n",
    "    if l in major_class:\n",
    "        label.append(0.0)\n",
    "    else:\n",
    "        label.append(1.0)\n",
    "dummies = pd.get_dummies(data=table, prefix=[\"Sex\"], columns=[\"Sex\"])\n",
    "attributes = [\"Sex_F\", \"Sex_I\", \"Sex_M\", \"Length\", \"Diameter\", \"Height\", \"Whole\", \"Shucked\", \"Viscera\", \"Shell\"]    \n",
    "data = dummies[attributes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n 为实验次数\n",
    "n = 100\n",
    "# 集成的模型个数\n",
    "ensemble = 3\n",
    "keys = [\"knn\", \"tree\", \"svm\", \"lgs\", \"nb\"]\n",
    "constructor = {\"knn\": KNeighborsClassifier, \"tree\": DecisionTreeClassifier, \"svm\": SVC, \n",
    "               \"lgs\": LogisticRegression, \"nb\": GaussianNB}\n",
    "algorithm_args = {\"knn\": {\"n_neighbors\": 7}, \"tree\": {}, \"svm\": {}, \"lgs\": {}, \"nb\": {}}\n",
    "algorithm = dict([(key, list()) for key in keys])\n",
    "for key in keys:\n",
    "    for i in range(ensemble):\n",
    "        construc = constructor[key]\n",
    "        args = algorithm_args[key]\n",
    "        alg = construc(**args)\n",
    "        algorithm[key].append(alg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn  :  gmean  :  0.5797634314419094-----------------knn  :  fscore  :  0.1941089100329932-----------------\n\ntree  :  gmean  :  0.4423392695868095-----------------tree  :  fscore  :  0.1342254246877389-----------------\n\nsvm  :  gmean  :  0.0-----------------svm  :  fscore  :  0.0-----------------\n\nlgs  :  gmean  :  0.4532615035456588-----------------lgs  :  fscore  :  0.16039667055667844-----------------\n\nnb  :  gmean  :  0.6360459488413123-----------------nb  :  fscore  :  0.14442101485899678-----------------\n\n"
     ]
    }
   ],
   "source": [
    "# 定义gmean函数\n",
    "def g_mean(ground_truth, prediction):\n",
    "    matrix = confusion_matrix(y_true=ground_truth, y_pred=prediction)\n",
    "    tpr = matrix[1, 1] / (matrix[1, 1] + matrix[1, 0])\n",
    "    tpn = matrix[0, 0] / (matrix[0, 0] + matrix[0, 1])\n",
    "    return np.sqrt(tpr * tpn)\n",
    "# 存储每次结果\n",
    "result = dict([(key, {\"gmean\": list(), \"fscore\": list()}) for key in algorithm.keys()])\n",
    "major = []\n",
    "minor = []\n",
    "major_label = []\n",
    "minor_label = []\n",
    "# 先将样本分为多数类和少数类\n",
    "for index in range(len(label)):\n",
    "    if label[index] == 1.0:\n",
    "        minor.append(data.iloc[index, :].tolist())\n",
    "        minor_label.append(1.0)\n",
    "    else:\n",
    "        major.append(data.iloc[index, :].tolist())\n",
    "        major_label.append(0.0)\n",
    "for i in range(n):\n",
    "    if i % 25 == 0:\n",
    "        print(\"round: \", i)\n",
    "    # 先将数据集分为训练和测试集\n",
    "    major_train, major_test, major_label_train, major_label_test = train_test_split(major, major_label, \n",
    "                                                                                    test_size=0.25, shuffle=True)\n",
    "    minor_train, minor_test, minor_label_train, minor_label_test = train_test_split(minor, minor_label, \n",
    "                                                                                    test_size=0.25, shuffle=True)\n",
    "    train = np.concatenate((major_train, minor_train), axis=0)\n",
    "    train_label = np.concatenate((major_label_train, minor_label_train), axis=0)\n",
    "    test = np.concatenate((major_test, minor_test))\n",
    "    test_label = np.concatenate((major_label_test, minor_label_test), axis=0)\n",
    "    predictions = dict((key, list()) for key in keys)\n",
    "    for j in range(ensemble):\n",
    "        kmeans_arg = {\"n_clusters\": 20}\n",
    "        over_sampler = Over_Sample(data=train, label=train_label, n=4, categorical_features=[0, 1, 2], **kmeans_arg)\n",
    "        syntheticed_samples = over_sampler.do_synthetic()\n",
    "        syntheticed_labels = len(syntheticed_samples) * [1.0]\n",
    "        under_sampler = Under_Sample(major=major_train, major_label=major_label_train, synthetics=syntheticed_samples,\n",
    "                                     synthetics_label=syntheticed_labels, categorical_features=[0, 1, 2], rate=1.0,\n",
    "                                     **kmeans_arg)\n",
    "        under_samples = under_sampler.do_undersample()\n",
    "        under_labels = len(under_samples) * [0.0]\n",
    "        over_under_samples = np.concatenate((minor_train, syntheticed_samples, under_samples), axis=0)\n",
    "        over_under_labels = np.concatenate((minor_label_train, syntheticed_labels, under_labels), axis=0)\n",
    "        for key in keys:\n",
    "            for alg in algorithm[key]:\n",
    "                alg.fit(X=over_under_samples, y=over_under_labels)\n",
    "                prediction = alg.predict(X=test)\n",
    "                predictions[key].append(prediction)\n",
    "    for key in keys:\n",
    "        prediction = predictions[key]\n",
    "        pre = []\n",
    "        for z, x, c in zip(prediction[0], prediction[1], prediction[2]):\n",
    "            if z == x:\n",
    "                pre.append(z)\n",
    "            else:\n",
    "                pre.append(c)\n",
    "        fscore = f1_score(y_true=test_label, y_pred=pre) / 2\n",
    "        gmean = g_mean(ground_truth=test_label, prediction=pre)\n",
    "        result[key][\"fscore\"].append(fscore)\n",
    "        result[key][\"gmean\"].append(gmean)\n",
    "new_line = 0       \n",
    "for alg_key in result.keys():\n",
    "    new_line += 1\n",
    "    alg = result[alg_key]\n",
    "    for score_key in alg.keys():\n",
    "        mean_score = np.mean(alg[score_key])\n",
    "        print(alg_key, \" : \", score_key, \" : \", mean_score, end=\"-----------------\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
