{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 导入当前项目路径以便找到自己写的包\n",
    "import sys\n",
    "sys.path.append(\"C:Users\\perma\\PycharmProjects\\paper\")\n",
    "from algorithm.km_smote import Over_Sample\n",
    "from algorithm.under_sample import Under_Sample\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: data, label 214 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\exe\\envs\\forpaper\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: read_table is deprecated, use read_csv instead.\n  \n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "column_names = [\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\", \"class\"]\n",
    "data_path = \"C:\\\\Users\\\\perma\\\\PycharmProjects\\\\paper\\\\data\\\\glass.data\"\n",
    "table = pd.read_table(filepath_or_buffer=data_path,\n",
    "                      sep=\",\",\n",
    "                      header=None,\n",
    "                      index_col=None,\n",
    "                      names=column_names)\n",
    "attributes = [\"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\"]\n",
    "data = table[attributes]\n",
    "label = table[\"class\"]\n",
    "print(\"length: data, label\", len(data), len(label))\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(X=data)\n",
    "scaled_data[0:3]\n",
    "minor_class = [5, 6, 7]\n",
    "major_class = [1, 2, 3, 4]\n",
    "new_label = []\n",
    "for l in label:\n",
    "    if l in major_class:\n",
    "        new_label.append(0.0)\n",
    "    else:\n",
    "        new_label.append(1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n 为实验次数\n",
    "n = 100\n",
    "# 集成的模型个数\n",
    "ensemble = 3\n",
    "keys = [\"knn\", \"tree\", \"svm\", \"lgs\", \"nb\"]\n",
    "constructor = {\"knn\": KNeighborsClassifier, \"tree\": DecisionTreeClassifier, \"svm\": SVC, \n",
    "               \"lgs\": LogisticRegression, \"nb\": GaussianNB}\n",
    "algorithm_args = {\"knn\": {\"n_neighbors\": 7}, \"tree\": {}, \"svm\": {}, \"lgs\": {}, \"nb\": {}}\n",
    "algorithm = dict([(key, list()) for key in keys])\n",
    "for key in keys:\n",
    "    for i in range(ensemble):\n",
    "        construc = constructor[key]\n",
    "        args = algorithm_args[key]\n",
    "        alg = construc(**args)\n",
    "        algorithm[key].append(alg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  25\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-42bbe9060cec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mkmeans_arg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"n_clusters\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mover_sampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOver_Sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkmeans_arg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0msyntheticed_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mover_sampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_synthetic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0msyntheticed_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msyntheticed_samples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         under_sampler = Under_Sample(major=major_train, major_label=major_label_train, synthetics=syntheticed_samples,\n",
      "\u001b[1;32m~\\PycharmProjects\\paper\\algorithm\\km_smote.py\u001b[0m in \u001b[0;36mdo_synthetic\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m                 \u001b[0msynth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mflag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                     \u001b[0msynth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynthesize_pure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcluster_point\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcluster_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mflag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                     \u001b[0msynth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynthesize_hybrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcluster_point\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcluster_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\paper\\algorithm\\km_smote.py\u001b[0m in \u001b[0;36msynthesize_pure\u001b[1;34m(self, data, label)\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m                 \u001b[0mindex_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m                 \u001b[0mpoint_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m                 \u001b[0msynthetic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynthesize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint_x\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoint_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpoint_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# 定义gmean函数\n",
    "def g_mean(ground_truth, prediction):\n",
    "    matrix = confusion_matrix(y_true=ground_truth, y_pred=prediction)\n",
    "    tpr = matrix[1, 1] / (matrix[1, 1] + matrix[1, 0])\n",
    "    tpn = matrix[0, 0] / (matrix[0, 0] + matrix[0, 1])\n",
    "    return np.sqrt(tpr * tpn)\n",
    "# 存储每次结果\n",
    "result = dict([(key, {\"gmean\": list(), \"fscore\": list()}) for key in algorithm.keys()])\n",
    "major = []\n",
    "minor = []\n",
    "major_label = []\n",
    "minor_label = []\n",
    "# 先将样本分为多数类和少数类\n",
    "for index in range(len(new_label)):\n",
    "    if new_label[index] == 1.0:\n",
    "        minor.append(scaled_data[index, :].tolist())\n",
    "        minor_label.append(1.0)\n",
    "    else:\n",
    "        major.append(scaled_data[index, :].tolist())\n",
    "        major_label.append(0.0)\n",
    "for i in range(n):\n",
    "    if i % 25 == 0:\n",
    "        print(\"round: \", i)\n",
    "    # 先将数据集分为训练和测试集\n",
    "    major_train, major_test, major_label_train, major_label_test = train_test_split(major, major_label, \n",
    "                                                                                    test_size=0.25, shuffle=True)\n",
    "    minor_train, minor_test, minor_label_train, minor_label_test = train_test_split(minor, minor_label, \n",
    "                                                                                    test_size=0.25, shuffle=True)\n",
    "    train = np.concatenate((major_train, minor_train), axis=0)\n",
    "    train_label = np.concatenate((major_label_train, minor_label_train), axis=0)\n",
    "    test = np.concatenate((major_test, minor_test))\n",
    "    test_label = np.concatenate((major_label_test, minor_label_test), axis=0)\n",
    "    predictions = dict((key, list()) for key in keys)\n",
    "    for j in range(ensemble):\n",
    "        kmeans_arg = {\"n_clusters\": 5}\n",
    "        over_sampler = Over_Sample(data=train, label=train_label, n=2, categorical_features=[], **kmeans_arg)\n",
    "        syntheticed_samples = over_sampler.do_synthetic()\n",
    "        syntheticed_labels = len(syntheticed_samples) * [1.0]\n",
    "        under_sampler = Under_Sample(major=major_train, major_label=major_label_train, synthetics=syntheticed_samples,\n",
    "                                     synthetics_label=syntheticed_labels, categorical_features=[], rate=0.7,\n",
    "                                     **kmeans_arg)\n",
    "        under_samples = under_sampler.do_undersample()\n",
    "        under_labels = len(under_samples) * [0.0]\n",
    "        over_under_samples = np.concatenate((minor_train, syntheticed_samples, under_samples), axis=0)\n",
    "        over_under_labels = np.concatenate((minor_label_train, syntheticed_labels, under_labels), axis=0)\n",
    "        for key in keys:\n",
    "            for alg in algorithm[key]:\n",
    "                alg.fit(X=over_under_samples, y=over_under_labels)\n",
    "                prediction = alg.predict(X=test)\n",
    "                predictions[key].append(prediction)\n",
    "    for key in keys:\n",
    "        prediction = predictions[key]\n",
    "        pre = []\n",
    "        for z, x, c in zip(prediction[0], prediction[1], prediction[2]):\n",
    "            if z == x:\n",
    "                pre.append(z)\n",
    "            else:\n",
    "                pre.append(c)\n",
    "        fscore = f1_score(y_true=test_label, y_pred=pre) / 2\n",
    "        gmean = g_mean(ground_truth=test_label, prediction=pre)\n",
    "        result[key][\"fscore\"].append(fscore)\n",
    "        result[key][\"gmean\"].append(gmean)\n",
    "new_line = 0       \n",
    "for alg_key in result.keys():\n",
    "    new_line += 1\n",
    "    alg = result[alg_key]\n",
    "    for score_key in alg.keys():\n",
    "        mean_score = np.mean(alg[score_key])\n",
    "        print(alg_key, \" : \", score_key, \" : \", mean_score, end=\"-----------------\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # under-sample-rate = 0.8\n",
    "# knn  :  gmean  :  0.9166897382228147-----------------knn  :  fscore  :  0.4312710976106651-----------------\n",
    "# \n",
    "# tree  :  gmean  :  0.8519224266667663-----------------tree  :  fscore  :  0.40228080306969977-----------------\n",
    "# \n",
    "# svm  :  gmean  :  0.8266906059127518-----------------svm  :  fscore  :  0.37762139419820007-----------------\n",
    "# \n",
    "# lgs  :  gmean  :  0.8509563756754943-----------------lgs  :  fscore  :  0.39812227682942875-----------------\n",
    "# \n",
    "# nb  :  gmean  :  0.8407995446029015-----------------nb  :  fscore  :  0.3972981784720915-----------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
