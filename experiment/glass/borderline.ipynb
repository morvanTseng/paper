{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# 直接导入Smote是不行的，必须将路径加入才可以\n",
    "sys.path.append(\"C:Users\\perma\\PycharmProjects\\paper\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from algorithm.border_line_smote import BSMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: data, label 214 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\exe\\envs\\forpaper\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: read_table is deprecated, use read_csv instead.\n  \n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "column_names = [\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\", \"class\"]\n",
    "data_path = \"C:\\\\Users\\\\perma\\\\PycharmProjects\\\\paper\\\\data\\\\glass.data\"\n",
    "table = pd.read_table(filepath_or_buffer=data_path,\n",
    "                      sep=\",\",\n",
    "                      header=None,\n",
    "                      index_col=None,\n",
    "                      names=column_names)\n",
    "attributes = [\"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\"]\n",
    "data = table[attributes]\n",
    "label = table[\"class\"]\n",
    "print(\"length: data, label\", len(data), len(label))\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(X=data)\n",
    "scaled_data[0:3]\n",
    "minor_class = [5, 6, 7]\n",
    "major_class = [1, 2, 3, 4]\n",
    "new_label = []\n",
    "for l in label:\n",
    "    if l in major_class:\n",
    "        new_label.append(0.0)\n",
    "    else:\n",
    "        new_label.append(1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "dc = DecisionTreeClassifier()\n",
    "svm = SVC()\n",
    "lg = LogisticRegression()\n",
    "nb = GaussianNB()\n",
    "algorithm = {\"knn\": knn, \"tree\": dc, \"svm\": svm, \"lgs\": lg, \"nb\": nb}\n",
    "alg_params = {\"knn\": {\"n_neighbors\": 7}, \n",
    "              \"tree\": {}, \n",
    "              \"svm\": {}, \n",
    "              \"lgs\": {}, \n",
    "              \"nb\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn  :  gmean  :  0.9368598383349245-----------------knn  :  fscore  :  0.4340045153241065-----------------\n\ntree  :  gmean  :  0.8997351795786162-----------------tree  :  fscore  :  0.41094055753465497-----------------\n\nsvm  :  gmean  :  0.6376286104382379-----------------svm  :  fscore  :  0.29755085070734-----------------\n\nlgs  :  gmean  :  0.6472642620208756-----------------lgs  :  fscore  :  0.27072673493563065-----------------\n\nnb  :  gmean  :  0.873278095102313-----------------nb  :  fscore  :  0.40031574993064223-----------------\n\n"
     ]
    }
   ],
   "source": [
    "# 将少数类和多数类分开提取出来\n",
    "major = []\n",
    "major_label = []\n",
    "minor = []\n",
    "minor_label = []\n",
    "for label_index in range(len(new_label)):\n",
    "    if new_label[label_index] == 1.0:\n",
    "        minor.append(scaled_data[label_index, :])\n",
    "        minor_label.append(new_label[label_index])\n",
    "    else:\n",
    "        major.append(scaled_data[label_index, :])\n",
    "        major_label.append(new_label[label_index])\n",
    "# 定义gmean函数\n",
    "def g_mean(ground_truth, prediction):\n",
    "    matrix = confusion_matrix(y_true=ground_truth, y_pred=prediction)\n",
    "    tpr = matrix[1, 1] / (matrix[1, 1] + matrix[1, 0])\n",
    "    tpn = matrix[0, 0] / (matrix[0, 0] + matrix[0, 1])\n",
    "    return np.sqrt(tpr * tpn)\n",
    "result = dict([(key, {\"gmean\": list(), \"fscore\": list()}) for key in algorithm.keys()])\n",
    "# 实验次数\n",
    "n=100\n",
    "for i in range(n):\n",
    "    for key in algorithm.keys():\n",
    "        alg = algorithm[key]\n",
    "        alg.set_params(**alg_params[key])\n",
    "        major_train, major_test, \\\n",
    "        major_label_train, major_label_test \\\n",
    "            = train_test_split(major, major_label, shuffle=True, test_size=0.25)\n",
    "        minor_train, minor_test, \\\n",
    "        minor_label_train, minor_label_test \\\n",
    "            = train_test_split(minor, minor_label, shuffle=True, test_size=0.25)\n",
    "        data_train = np.concatenate((major_train, minor_train), axis=0)\n",
    "        label_train = np.concatenate((major_label_train, minor_label_train), axis=0)\n",
    "        data_test = np.concatenate((major_test, minor_test), axis=0)\n",
    "        label_test = np.concatenate((major_label_test, minor_label_test), axis=0)\n",
    "        # smote生成合成样本\n",
    "        \n",
    "        bsmote = BSMOTE(data=data_train, label=label_train, K=8, sample_ratio=300)\n",
    "        syntheticed_samples = bsmote.over_sample()\n",
    "        syntheticed_labels = len(syntheticed_samples) * [1.0]\n",
    "        syntheticed_train = np.concatenate((data_train, syntheticed_samples), axis=0)\n",
    "        syntheticed_train_label = np.concatenate((label_train, syntheticed_labels), axis=0)\n",
    "        alg.fit(X=syntheticed_train, y=syntheticed_train_label)\n",
    "        prediction = alg.predict(X=data_test)\n",
    "        gmean = g_mean(label_test, prediction)\n",
    "        fscore = f1_score(y_true=label_test, y_pred=prediction) / 2\n",
    "        result[key][\"gmean\"].append(gmean)\n",
    "        result[key][\"fscore\"].append(fscore)\n",
    "new_line = 0       \n",
    "for alg_key in result.keys():\n",
    "    new_line += 1\n",
    "    alg = result[alg_key]\n",
    "    for score_key in alg.keys():\n",
    "        mean_score = np.mean(alg[score_key])\n",
    "        print(alg_key, \" : \", score_key, \" : \", mean_score, end=\"-----------------\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # k = 3\n",
    "# knn  :  gmean  :  0.9348490383699027-----------------knn  :  fscore  :  0.4375843161804127-----------------\n",
    "# \n",
    "# tree  :  gmean  :  0.8981911831517609-----------------tree  :  fscore  :  0.4135927565030294-----------------\n",
    "# \n",
    "# svm  :  gmean  :  0.8773485036519649-----------------svm  :  fscore  :  0.40470147535457734-----------------\n",
    "# \n",
    "# lgs  :  gmean  :  0.9098995656866761-----------------lgs  :  fscore  :  0.40862972432828654-----------------\n",
    "# \n",
    "# nb  :  gmean  :  0.8752822586529576-----------------nb  :  fscore  :  0.40157479927890305-----------------\n",
    "# \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
