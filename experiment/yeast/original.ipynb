{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"C:Users\\perma\\PycharmProjects\\paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将少数类样本的类标签变为数字\n",
    "def turn_name_to_num(name):\n",
    "    names = [\"ME2\", \"ME1\", \"EXC\", \"VAC\", \"POX\", \"ERL\"]            \n",
    "    if name in names:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "# 处理数据的总函数\n",
    "def process(data_path):\n",
    "    names = [\"Sequence Name\", \"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\", \"nuc\", \"class\"]\n",
    "    data = pd.read_table(filepath_or_buffer=data_path, \n",
    "                         header=None, \n",
    "                         index_col=None, \n",
    "                         names=names, \n",
    "                         sep=\"\\s+\")\n",
    "    data[\"class\"] = data[\"class\"].apply(turn_name_to_num)\n",
    "    columns = [\"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\", \"nuc\"]\n",
    "    data_ = data[columns]\n",
    "    label = data[\"class\"]\n",
    "    return data_, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\exe\\envs\\forpaper\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: read_table is deprecated, use read_csv instead.\n  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "root_path = \"C:\\\\Users\\\\perma\\\\PycharmProjects\\\\paper\"\n",
    "data_path = root_path + \"\\\\data\\\\yeast.data\"\n",
    "data, label = process(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mcg   gvh   alm   mit  erl  pox   vac   nuc\n0  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22\n1  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22\n2  0.64  0.62  0.49  0.15  0.5  0.0  0.53  0.22\ndata shape: (1484, 8) label shape (1484,)\n0    0.0\n1    0.0\n2    0.0\nName: class, dtype: float64\n1_count 185 0_count 1299\n"
     ]
    }
   ],
   "source": [
    "print(data.head(3))\n",
    "print(\"data shape:\", data.shape, \"label shape\", label.shape)\n",
    "print(label.head(3))\n",
    "c1 = 0 \n",
    "c0 = 0\n",
    "for c in label:\n",
    "    if c == 1.0:\n",
    "        c1 += 1\n",
    "    else:\n",
    "        c0 += 1\n",
    "print(\"1_count\", c1, \"0_count\", c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "dc = DecisionTreeClassifier()\n",
    "svm = SVC()\n",
    "lg = LogisticRegression()\n",
    "nb = GaussianNB()\n",
    "algorithm = {\"knn\": knn, \"tree\": dc, \"svm\": svm, \"lgs\": lg, \"nb\": nb}\n",
    "alg_params = {\"knn\": {\"n_neighbors\": 7}, \n",
    "              \"tree\": {}, \n",
    "              \"svm\": {}, \n",
    "              \"lgs\": {}, \n",
    "              \"nb\": {}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\"n_neighbors\": (3, 5, 7, 9, 13, 15, 17, 19)}\n",
    "tree_params = {\"criterion\": (\"gini\", \"entropy\")}\n",
    "svm_params = {\"degree\": (3, 4, 5, 6, 7, 8)}\n",
    "lg_params = {\"penalty\": (\"l1\", \"l2\")}\n",
    "nb_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到knn算法最好的n_neighbor参数为7\n",
    "grid = GridSearchCV(estimator=knn, param_grid=knn_params, scoring=\"f1\", cv=5)\n",
    "grid.fit(X=data, y=label)\n",
    "grid.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将少数类和多数类分开提取出来\n",
    "major = []\n",
    "major_label = []\n",
    "minor = []\n",
    "minor_label = []\n",
    "for label_index in range(len(label)):\n",
    "    if label[label_index] == 1.0:\n",
    "        minor.append(data.iloc[label_index, :])\n",
    "        minor_label.append(label[label_index])\n",
    "    else:\n",
    "        major.append(data.iloc[label_index, :])\n",
    "        major_label.append(label[label_index])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn  :  gmean  :  0.7789863597508483-----------------knn  :  fscore  :  0.35595590780611425-----------------\n\ntree  :  gmean  :  0.7757417570109364-----------------tree  :  fscore  :  0.31180409066606035-----------------\n\nsvm  :  gmean  :  0.37795288714941416-----------------svm  :  fscore  :  0.12716273733057648-----------------\n\nlgs  :  gmean  :  0.624680951757748-----------------lgs  :  fscore  :  0.2773484905534051-----------------\n\nnb  :  gmean  :  0.7551352636441806-----------------nb  :  fscore  :  0.3387135084266024-----------------\n\n"
     ]
    }
   ],
   "source": [
    "# 定义gmean函数\n",
    "def g_mean(ground_truth, prediction):\n",
    "    matrix = confusion_matrix(y_true=ground_truth, y_pred=prediction)\n",
    "    tpr = matrix[1, 1] / (matrix[1, 1] + matrix[1, 0])\n",
    "    tpn = matrix[0, 0] / (matrix[0, 0] + matrix[0, 1])\n",
    "    return np.sqrt(tpr * tpn)\n",
    "result = dict([(key, {\"gmean\": list(), \"fscore\": list()}) for key in algorithm.keys()])\n",
    "# 实验次数\n",
    "n=100\n",
    "for i in range(n):\n",
    "    for key in algorithm.keys():\n",
    "        alg = algorithm[key]\n",
    "        alg.set_params(**alg_params[key])\n",
    "        major_train, major_test, \\\n",
    "        major_label_train, major_label_test \\\n",
    "            = train_test_split(major, major_label, shuffle=True, test_size=0.25)\n",
    "        minor_train, minor_test, \\\n",
    "        minor_label_train, minor_label_test \\\n",
    "            = train_test_split(minor, minor_label, shuffle=True, test_size=0.25)\n",
    "        data_train = np.concatenate((major_train, minor_train), axis=0)\n",
    "        label_train = np.concatenate((major_label_train, minor_label_train), axis=0)\n",
    "        data_test = np.concatenate((major_test, minor_test), axis=0)\n",
    "        label_test = np.concatenate((major_label_test, minor_label_test), axis=0)\n",
    "        alg.fit(X=data_train, y=label_train)\n",
    "        prediction = alg.predict(X=data_test)\n",
    "        gmean = g_mean(label_test, prediction)\n",
    "        fscore = f1_score(y_true=label_test, y_pred=prediction) / 2\n",
    "        result[key][\"gmean\"].append(gmean)\n",
    "        result[key][\"fscore\"].append(fscore)\n",
    "new_line = 0       \n",
    "for alg_key in result.keys():\n",
    "    new_line += 1\n",
    "    alg = result[alg_key]\n",
    "    for score_key in alg.keys():\n",
    "        mean_score = np.mean(alg[score_key])\n",
    "        print(alg_key, \" : \", score_key, \" : \", mean_score, end=\"-----------------\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alg: knn   fscore:  0.35728248455488953\nalg: tree   fscore:  0.30652186705583273\nalg: svm   fscore:  0.131164988681498\nalg: lgs   fscore:  0.2757027674457761\nalg: nb   fscore:  0.34575272850003214\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alg: knn   gmean_score:  0.7810731699159459\nalg: tree   gmean_score:  0.7743889555021399\nalg: svm   gmean_score:  0.38365806518827805\nalg: lgs   gmean_score:  0.6213288758758633\nalg: nb   gmean_score:  0.7662581729709167\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
