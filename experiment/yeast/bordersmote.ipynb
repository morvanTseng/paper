{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 导入当前项目路径以便找到自己写的包\n",
    "import sys\n",
    "sys.path.append(\"C:Users\\perma\\PycharmProjects\\paper\")\n",
    "from algorithm.SMOTE import Smote\n",
    "from algorithm.border_line_smote import BSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mcg   gvh   alm   mit  erl  pox   vac   nuc\n0  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22\n1  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22\n2  0.64  0.62  0.49  0.15  0.5  0.0  0.53  0.22\ndata shape: (1484, 8) label shape (1484,)\n0    0.0\n1    0.0\n2    0.0\nName: class, dtype: float64\n1_count 185 0_count 1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\exe\\envs\\forpaper\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: read_table is deprecated, use read_csv instead.\n  \n"
     ]
    }
   ],
   "source": [
    "def turn_name_to_num(name):\n",
    "    names = [\"ME2\", \"ME1\", \"EXC\", \"VAC\", \"POX\", \"ERL\"]            \n",
    "    if name in names:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "# 处理数据的总函数\n",
    "def process(data_path):\n",
    "    names = [\"Sequence Name\", \"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\", \"nuc\", \"class\"]\n",
    "    data = pd.read_table(filepath_or_buffer=data_path, \n",
    "                         header=None, \n",
    "                         index_col=None, \n",
    "                         names=names, \n",
    "                         sep=\"\\s+\")\n",
    "    data[\"class\"] = data[\"class\"].apply(turn_name_to_num)\n",
    "    columns = [\"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\", \"nuc\"]\n",
    "    data_ = data[columns]\n",
    "    label = data[\"class\"]\n",
    "    return data_, label\n",
    "root_path = \"C:\\\\Users\\\\perma\\\\PycharmProjects\\\\paper\"\n",
    "data_path = root_path + \"\\\\data\\\\yeast.data\"\n",
    "data, label = process(data_path)\n",
    "print(data.head(3))\n",
    "print(\"data shape:\", data.shape, \"label shape\", label.shape)\n",
    "print(label.head(3))\n",
    "c1 = 0 \n",
    "c0 = 0\n",
    "for c in label:\n",
    "    if c == 1.0:\n",
    "        c1 += 1\n",
    "    else:\n",
    "        c0 += 1\n",
    "print(\"1_count\", c1, \"0_count\", c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "dc = DecisionTreeClassifier()\n",
    "svm = SVC()\n",
    "lg = LogisticRegression()\n",
    "nb = GaussianNB()\n",
    "algorithm = {\"knn\": knn, \"tree\": dc, \"svm\": svm, \"lgs\": lg, \"nb\": nb}\n",
    "alg_params = {\"knn\": {\"n_neighbors\": 7}, \n",
    "              \"tree\": {}, \n",
    "              \"svm\": {}, \n",
    "              \"lgs\": {}, \n",
    "              \"nb\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这种实验有很多预测对的少数类样本是属于生成的样本，并不能代表对实际少数类的真实预测情况\n",
    "# original的可以代表对真实的预测情况\n",
    "# 所以决定用合成少数类来训练样本，把真实的样本留在预测\n",
    "# 或者预留一部分作为测试集\n",
    "# 设实验次数为n\n",
    "# for i in range(n):\n",
    "#    将数据集分为训练集和测试集，每个类样本的在训练集和测试集比例为3：1\n",
    "#    在训练集上合成数据训练模型\n",
    "#    在测试集上测试结果\n",
    "#取n次实验结果的平均值为最终成绩\n",
    "\n",
    "# 我自己的算法不一样需要改一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn  :  gmean  :  0.8398893737570391-----------------knn  :  fscore  :  0.36734741095559864-----------------\n\ntree  :  gmean  :  0.8152896506109473-----------------tree  :  fscore  :  0.30562540771322605-----------------\n\nsvm  :  gmean  :  0.8371460346475702-----------------svm  :  fscore  :  0.3747214546526932-----------------\n\nlgs  :  gmean  :  0.8451608257854448-----------------lgs  :  fscore  :  0.36127969670961746-----------------\n\nnb  :  gmean  :  0.7501498491145482-----------------nb  :  fscore  :  0.3310565152460449-----------------\n\n"
     ]
    }
   ],
   "source": [
    "# 定义gmean函数\n",
    "def g_mean(ground_truth, prediction):\n",
    "    matrix = confusion_matrix(y_true=ground_truth, y_pred=prediction)\n",
    "    tpr = matrix[1, 1] / (matrix[1, 1] + matrix[1, 0])\n",
    "    tpn = matrix[0, 0] / (matrix[0, 0] + matrix[0, 1])\n",
    "    return np.sqrt(tpr * tpn)\n",
    "# 存储每次结果\n",
    "result = dict([(key, {\"gmean\": list(), \"fscore\": list()}) for key in algorithm.keys()])\n",
    "# n 为实验次数\n",
    "n = 100\n",
    "major = []\n",
    "minor = []\n",
    "major_label = []\n",
    "minor_label = []\n",
    "# 先将样本分为多数类和少数类\n",
    "for index in range(len(label)):\n",
    "    if label[index] == 1.0:\n",
    "        minor.append(data.iloc[index, :])\n",
    "        minor_label.append(1.0)\n",
    "    else:\n",
    "        major.append(data.iloc[index, :])\n",
    "        major_label.append(0.0)\n",
    "for i in range(n):\n",
    "    # 先将数据集分为训练和测试集\n",
    "    major_train, major_test, major_label_train, major_label_test = train_test_split(major, major_label, \n",
    "                                                                                    test_size=0.25, shuffle=True)\n",
    "    minor_train, minor_test, minor_label_train, minor_label_test = train_test_split(minor, minor_label, \n",
    "                                                                                    test_size=0.25, shuffle=True)\n",
    "    train = np.concatenate((major_train, minor_train), axis=0)\n",
    "    train_label = np.concatenate((major_label_train, minor_label_train), axis=0)\n",
    "    test = np.concatenate((major_test, minor_test))\n",
    "    test_label = np.concatenate((major_label_test, minor_label_test), axis=0)\n",
    "    # smote生成合成样本\n",
    "    bsmote = BSMOTE(data=data.values, label=label.tolist(), K=1, sample_ratio=700)\n",
    "    syntheticed_samples = bsmote.over_sample()\n",
    "    syntheticed_labels = len(syntheticed_samples) * [1.0]\n",
    "    syntheticed_train = np.concatenate((train, syntheticed_samples), axis=0)\n",
    "    syntheticed_train_label = np.concatenate((train_label, syntheticed_labels), axis=0)\n",
    "    # 对每个算法都测试一遍\n",
    "    for key in algorithm.keys():\n",
    "        alg = algorithm[key]\n",
    "        alg.set_params(**alg_params[key])\n",
    "        alg.fit(X=syntheticed_train, y=syntheticed_train_label)\n",
    "        prediction = alg.predict(X=test)\n",
    "        gmean = g_mean(ground_truth=test_label, prediction=prediction)\n",
    "        fscore = f1_score(y_true=test_label, y_pred=prediction) / 2\n",
    "        result[key][\"gmean\"].append(gmean)\n",
    "        result[key][\"fscore\"].append(fscore)\n",
    "new_line = 0       \n",
    "for alg_key in result.keys():\n",
    "    new_line += 1\n",
    "    alg = result[alg_key]\n",
    "    for score_key in alg.keys():\n",
    "        mean_score = np.mean(alg[score_key])\n",
    "        print(alg_key, \" : \", score_key, \" : \", mean_score, end=\"-----------------\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # K = 2\n",
    "# sample_ratio = 700\n",
    "# knn  :  gmean  :  0.8424752755807984-----------------knn  :  fscore  :  0.37828882426098615-----------------\n",
    "# \n",
    "# tree  :  gmean  :  0.8318476022482021-----------------tree  :  fscore  :  0.33640695876489857-----------------\n",
    "# \n",
    "# svm  :  gmean  :  0.8439824558899357-----------------svm  :  fscore  :  0.36216013952759546-----------------\n",
    "# \n",
    "# lgs  :  gmean  :  0.8406605242457555-----------------lgs  :  fscore  :  0.35629085501026125-----------------\n",
    "# \n",
    "# nb  :  gmean  :  0.8204527031844523-----------------nb  :  fscore  :  0.3616999670677615-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 1\n",
    "# sample_ratio = 700\n",
    "# knn  :  gmean  :  0.8398893737570391-----------------knn  :  fscore  :  0.36734741095559864-----------------\n",
    "# \n",
    "# tree  :  gmean  :  0.8152896506109473-----------------tree  :  fscore  :  0.30562540771322605-----------------\n",
    "# \n",
    "# svm  :  gmean  :  0.8371460346475702-----------------svm  :  fscore  :  0.3747214546526932-----------------\n",
    "# \n",
    "# lgs  :  gmean  :  0.8451608257854448-----------------lgs  :  fscore  :  0.36127969670961746-----------------\n",
    "# \n",
    "# nb  :  gmean  :  0.7501498491145482-----------------nb  :  fscore  :  0.3310565152460449-------------\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
