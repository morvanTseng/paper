{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 导入当前项目路径以便找到自己写的包\n",
    "import sys\n",
    "sys.path.append(\"C:Users\\perma\\PycharmProjects\\paper\")\n",
    "from algorithm.km_smote import Over_Sample\n",
    "from algorithm.under_sample import Under_Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mcg   gvh   alm   mit  erl  pox   vac   nuc\n0  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22\n1  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22\n2  0.64  0.62  0.49  0.15  0.5  0.0  0.53  0.22\ndata shape: (1484, 8) label shape (1484,)\n0    0.0\n1    0.0\n2    0.0\nName: class, dtype: float64\n1_count 185 0_count 1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\exe\\envs\\forpaper\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: read_table is deprecated, use read_csv instead.\n  \n"
     ]
    }
   ],
   "source": [
    "def turn_name_to_num(name):\n",
    "    names = [\"ME2\", \"ME1\", \"EXC\", \"VAC\", \"POX\", \"ERL\"]            \n",
    "    if name in names:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "# 处理数据的总函数\n",
    "def process(data_path):\n",
    "    names = [\"Sequence Name\", \"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\", \"nuc\", \"class\"]\n",
    "    data = pd.read_table(filepath_or_buffer=data_path, \n",
    "                         header=None, \n",
    "                         index_col=None, \n",
    "                         names=names, \n",
    "                         sep=\"\\s+\")\n",
    "    data[\"class\"] = data[\"class\"].apply(turn_name_to_num)\n",
    "    columns = [\"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\", \"nuc\"]\n",
    "    data_ = data[columns]\n",
    "    label = data[\"class\"]\n",
    "    return data_, label\n",
    "root_path = \"C:\\\\Users\\\\perma\\\\PycharmProjects\\\\paper\"\n",
    "data_path = root_path + \"\\\\data\\\\yeast.data\"\n",
    "data, label = process(data_path)\n",
    "print(data.head(3))\n",
    "print(\"data shape:\", data.shape, \"label shape\", label.shape)\n",
    "print(label.head(3))\n",
    "c1 = 0 \n",
    "c0 = 0\n",
    "for c in label:\n",
    "    if c == 1.0:\n",
    "        c1 += 1\n",
    "    else:\n",
    "        c0 += 1\n",
    "print(\"1_count\", c1, \"0_count\", c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn = KNeighborsClassifier()\n",
    "# dc = DecisionTreeClassifier()\n",
    "# svm = SVC()\n",
    "# lg = LogisticRegression()\n",
    "# nb = GaussianNB()\n",
    "# algorithm = {\"knn\": knn, \"tree\": dc, \"svm\": svm, \"lgs\": lg, \"nb\": nb}\n",
    "# alg_params = {\"knn\": {\"n_neighbors\": 7}, \n",
    "#               \"tree\": {}, \n",
    "#               \"svm\": {}, \n",
    "#               \"lgs\": {}, \n",
    "#               \"nb\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这种实验有很多预测对的少数类样本是属于生成的样本，并不能代表对实际少数类的真实预测情况\n",
    "# original的可以代表对真实的预测情况\n",
    "# 所以决定用合成少数类来训练样本，把真实的样本留在预测\n",
    "# 或者预留一部分作为测试集\n",
    "# 设实验次数为n\n",
    "# for i in range(n):\n",
    "#    将数据集分为训练集和测试集，每个类样本的在训练集和测试集比例为3：1\n",
    "#    在训练集上合成数据训练模型\n",
    "#    在测试集上测试结果\n",
    "#取n次实验结果的平均值为最终成绩\n",
    "\n",
    "# 我自己的算法不一样需要改一下\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n 为实验次数\n",
    "n = 100\n",
    "# 集成的模型个数\n",
    "ensemble = 3\n",
    "keys = [\"knn\", \"tree\", \"svm\", \"lgs\", \"nb\"]\n",
    "constructor = {\"knn\": KNeighborsClassifier, \"tree\": DecisionTreeClassifier, \"svm\": SVC, \n",
    "               \"lgs\": LogisticRegression, \"nb\": GaussianNB}\n",
    "algorithm_args = {\"knn\": {\"n_neighbors\": 7}, \"tree\": {}, \"svm\": {}, \"lgs\": {}, \"nb\": {}}\n",
    "algorithm = dict([(key, list()) for key in keys])\n",
    "for key in keys:\n",
    "    for i in range(ensemble):\n",
    "        construc = constructor[key]\n",
    "        args = algorithm_args[key]\n",
    "        alg = construc(**args)\n",
    "        algorithm[key].append(alg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:  75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn  :  gmean  :  0.0-----------------knn  :  fscore  :  0.11217183770883052-----------------\n\ntree  :  gmean  :  0.30680159814357977-----------------tree  :  fscore  :  0.11944375881250113-----------------\n\nsvm  :  gmean  :  0.0-----------------svm  :  fscore  :  0.11217183770883052-----------------\n\nlgs  :  gmean  :  0.0-----------------lgs  :  fscore  :  0.11217183770883052-----------------\n\nnb  :  gmean  :  0.3592642997462769-----------------nb  :  fscore  :  0.1176470119437251-----------------\n\n"
     ]
    }
   ],
   "source": [
    "# 定义gmean函数\n",
    "def g_mean(ground_truth, prediction):\n",
    "    matrix = confusion_matrix(y_true=ground_truth, y_pred=prediction)\n",
    "    tpr = matrix[1, 1] / (matrix[1, 1] + matrix[1, 0])\n",
    "    tpn = matrix[0, 0] / (matrix[0, 0] + matrix[0, 1])\n",
    "    return np.sqrt(tpr * tpn)\n",
    "# 存储每次结果\n",
    "result = dict([(key, {\"gmean\": list(), \"fscore\": list()}) for key in algorithm.keys()])\n",
    "major = []\n",
    "minor = []\n",
    "major_label = []\n",
    "minor_label = []\n",
    "# 先将样本分为多数类和少数类\n",
    "for index in range(len(label)):\n",
    "    if label[index] == 1.0:\n",
    "        minor.append(data.iloc[index, :].to_list())\n",
    "        minor_label.append(1.0)\n",
    "    else:\n",
    "        major.append(data.iloc[index, :].to_list())\n",
    "        major_label.append(0.0)\n",
    "for i in range(n):\n",
    "    if i % 25 == 0:\n",
    "        print(\"round: \", i)\n",
    "    # 先将数据集分为训练和测试集\n",
    "    major_train, major_test, major_label_train, major_label_test = train_test_split(major, major_label, \n",
    "                                                                                    test_size=0.25, shuffle=True)\n",
    "    minor_train, minor_test, minor_label_train, minor_label_test = train_test_split(minor, minor_label, \n",
    "                                                                                    test_size=0.25, shuffle=True)\n",
    "    train = np.concatenate((major_train, minor_train), axis=0)\n",
    "    train_label = np.concatenate((major_label_train, minor_label_train), axis=0)\n",
    "    test = np.concatenate((major_test, minor_test))\n",
    "    test_label = np.concatenate((major_label_test, minor_label_test), axis=0)\n",
    "    predictions = dict((key, list()) for key in keys)\n",
    "    for j in range(ensemble):\n",
    "        kmeans_arg = {\"n_clusters\": 10}\n",
    "        over_sampler = Over_Sample(data=train, label=train_label, n=5, categorical_features=[], **kmeans_arg)\n",
    "        syntheticed_samples = over_sampler.do_synthetic()\n",
    "        syntheticed_labels = len(syntheticed_samples) * [1.0]\n",
    "        under_sampler = Under_Sample(major=major_train, major_label=major_label_train, synthetics=syntheticed_samples,\n",
    "                                     synthetics_label=syntheticed_labels, categorical_features=[], rate=0.0,\n",
    "                                     **kmeans_arg)\n",
    "        under_samples = under_sampler.do_undersample()\n",
    "        under_labels = len(under_samples) * [0.0]\n",
    "        over_under_samples = np.concatenate((syntheticed_samples, under_samples), axis=0)\n",
    "        over_under_labels = np.concatenate((syntheticed_labels, under_labels), axis=0)\n",
    "        for key in keys:\n",
    "            for alg in algorithm[key]:\n",
    "                alg.fit(X=over_under_samples, y=over_under_labels)\n",
    "                prediction = alg.predict(X=test)\n",
    "                predictions[key].append(prediction)\n",
    "    for key in keys:\n",
    "        prediction = predictions[key]\n",
    "        pre = []\n",
    "        for z, x, c in zip(prediction[0], prediction[1], prediction[2]):\n",
    "            if z == x:\n",
    "                pre.append(z)\n",
    "            else:\n",
    "                pre.append(c)\n",
    "        fscore = f1_score(y_true=test_label, y_pred=pre) / 2\n",
    "        gmean = g_mean(ground_truth=test_label, prediction=pre)\n",
    "        result[key][\"fscore\"].append(fscore)\n",
    "        result[key][\"gmean\"].append(gmean)\n",
    "new_line = 0       \n",
    "for alg_key in result.keys():\n",
    "    new_line += 1\n",
    "    alg = result[alg_key]\n",
    "    for score_key in alg.keys():\n",
    "        mean_score = np.mean(alg[score_key])\n",
    "        print(alg_key, \" : \", score_key, \" : \", mean_score, end=\"-----------------\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensem = 3\n",
    "#kmeans_arg = {\"n_clusters\": 10}\n",
    "# rate =0.5\n",
    "# over_sampe n = 6\n",
    "# knn  :  gmean  :  0.8161940257044472-----------------knn  :  fscore  :  0.29362386974321875-----------------\n",
    "# \n",
    "# tree  :  gmean  :  0.6770887577269807-----------------tree  :  fscore  :  0.2337023040470957-----------------\n",
    "# \n",
    "# svm  :  gmean  :  0.8419578240385807-----------------svm  :  fscore  :  0.34976042979187627-----------------\n",
    "# \n",
    "# lgs  :  gmean  :  0.8177024627267186-----------------lgs  :  fscore  :  0.3499989420274296-----------------\n",
    "# \n",
    "# nb  :  gmean  :  0.801173567270654-----------------nb  :  fscore  :  0.3248447740605052-----------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble = 3\n",
    "# kmeans_arg = {\"n_clusters\": 20}\n",
    "# over_sample n = 6\n",
    "# under_sample rate = 0.5\n",
    "# knn  :  gmean  :  0.8193007161501623-----------------knn  :  fscore  :  0.2950527637111551-----------------\n",
    "# \n",
    "# tree  :  gmean  :  0.7054201631703559-----------------tree  :  fscore  :  0.2461424484415236-----------------\n",
    "# \n",
    "# svm  :  gmean  :  0.8478393353679243-----------------svm  :  fscore  :  0.3544252798104335-----------------\n",
    "# \n",
    "# lgs  :  gmean  :  0.8312384224759848-----------------lgs  :  fscore  :  0.3511362949594299-----------------\n",
    "# \n",
    "# nb  :  gmean  :  0.7928233472575573-----------------nb  :  fscore  :  0.3317873151455374-----------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
